# (Optional) Template file given by the user to evaluate the search system using relevance judgements generated by the
# dataset-generator module
# Default: no template is being used
# Example (solr):
query_template: "templates/template_solr.json"

# Type of search engine to use
# Accepted values: solr, elasticsearch, opensearch, vespa
search_engine_type: "solr"

# Name of the search engine index/collection
collection_name: "testcore"

# URL of the search engine
# opensearch: http://localhost:9200/
search_engine_url: "http://localhost:8983/solr/"

# (Optional) Filter query to restrict the set of documents used to generate queries.
# If a field has more than one value, the documents retrieved have at least one of the values in the field (OR-
# -like). If there are more than one fields, the documents are filtered for both fields (AND-like)
# Default: all documents are considered and no filter is applied
#documents_filter:
#  - genre:
#      - "horror"
#      - "fantasy"
#  - type:
#      - "book"

# Maximum number of documents to retrieve from the search engine to generate queries
number_of_docs: 2

# List of fields from documents used to generate queries and relevance scoring
# These should match fields available in the search engine schema
# Must be at least one field
doc_fields:
  - "title"
  - "description"
  - "content"

# (Optional) File containing predefined queries to use instead of or alongside generated ones
# If available, must be in a txt format.
#queries: "templates/queries.txt"

# (Optional) Whether to generate queries from documents
# Default: true; set to false to disable query generation from documents
generate_queries_from_documents: true

# Total number of queries to generate (includes predefined queries, if any)
num_queries_needed: 4

# Relevance scale used for scoring document relevance
# Accepted values:
#   - binary: 0 (not relevant), 1 (relevant)
#   - graded: 0 (not relevant), 1 (maybe ok), 2 (thatâ€™s my result)
relevance_scale: "graded"

# Path to the LLM configuration file (e.g., LangChain setup)
llm_configuration_file: "configs/dataset_generator/llm_config.yaml"

# (Optional) max number of query terms to be generated by the LLM
# max_query_terms: 5

# Output format for the generated dataset
# Accepted values: quepid, rre, mteb
output_format: "quepid"

# For rre output format, you need other fields, e.g.:
#id_field: "id"
#rre_query_template: "templates/only_vector.json" # optional, if not filled, is the same as query_template
#rre_query_placeholder: "$query"

# Path where the output dataset will be saved
# For rre, output dataset will be saved into output_destination/"ratings.json"
# For quepid, output dataset will be saved into output_destination/"quepid.csv"
# For mteb, the following three files will be saved into: corpus.jsonl, queries.jsonl, and candidates.jsonl
# corpus.jsonl contains <id,title,text> corpus records extracted from search engine.
# queries.jsonl contains <id,text> query records LLM-generated and/or user-defined.
# candidates.jsonl contains <query_id,doc_id,rating> candidate records.
output_destination: "resources"

# (Optional) Whether to save LLM rating score explanation to file
# Default: false; set to true to save LLM rating explanation
#save_llm_explanation: true

# (Optional**) File path where it contains <query, doc_id, rating, explanation> records.
# (**) When save_llm_explanation is set to True, this param needs to be present
#llm_explanation_destination: "resources/rating_explanation.json"

# (Optional) Periodically persist in-memory datastore every N successful updates
# Lower values persist more frequently (safer) but can be slower; higher values persist less often (faster)
#datastore_autosave_every_n_updates: 50
