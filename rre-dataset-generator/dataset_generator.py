# configuration params
from src.config import Config
from src.utils import parse_args
from src.llm.llm_config import LLMConfig

# data types
from typing import List
from langchain_core.language_models import BaseChatModel
from src.llm.llm_service import LLMService
from src.model.document import Document
from src.writers.abstract_writer import AbstractWriter
from src.search_engine.search_engine_base import BaseSearchEngine
from src.model.query_response import LLMQueryResponse
from src.model.score_response import LLMScoreResponse

# data structure
from src.search_engine.data_store import DataStore

# build factories
from src.llm.llm_provider_factory import LLMServiceFactory
from src.writers.writer_factory import WriterFactory
from src.search_engine.search_engine_factory import SearchEngineFactory

# logging
from src.logger import configure_logging
from logging import Logger, getLogger, DEBUG, INFO


def get_and_setup_logging(verbose: bool = False) -> Logger:
    if verbose:
        configure_logging(DEBUG)
    else:
        configure_logging(INFO)

    return getLogger(__name__)


def add_user_queries(config: Config, data_store: DataStore):
    if config.queries is not None:
        with open(config.queries, 'r', encoding='utf-8') as file:
            for line in file:
                cleaned = line.strip()
                if cleaned:
                    data_store.add_query(cleaned)


def generate_and_add_queries(config: Config, data_store: DataStore, llm_service: LLMService, docs_to_generate_queries: List[Document]) -> None:
    num_queries_per_doc: int = int(
        ((config.num_queries_needed - len(data_store.get_queries())) // config.doc_number) * 1.5)

    for doc in docs_to_generate_queries:
        data_store.add_document(doc.id, doc)
        query_response: LLMQueryResponse = llm_service.generate_queries(doc, num_queries_per_doc)
        for query_text in query_response.get_queries():
            if len(data_store.get_queries()) >= config.num_queries_needed:
                return
            query_id: str = data_store.add_query(query_text, doc.id)
            data_store.add_rating_score(query_id, doc.id, max(config.relevance_label_set),
                                        "Default max rating is assigned because the query is generated by the document")


def retrieve_and_add_documents(config: Config, data_store: DataStore, search_engine: BaseSearchEngine) -> None:
    for query_rating_context in data_store.get_queries():
        docs_eval: List[Document] = search_engine.fetch_for_evaluation(keyword=query_rating_context.get_query_text(),
                                                                       query_template=config.query_template,
                                                                       doc_fields=config.doc_fields)
        for doc in docs_eval:
            if not data_store.has_document(doc.id):
                data_store.add_document(doc.id, doc)

def add_cartesian_product_scores(config: Config, data_store: DataStore, llm_service: LLMService) -> None:
    for query_rating_context in data_store.get_queries():
        for doc in data_store.get_documents():
            if not data_store.has_rating_score(query_rating_context.get_query_id(), doc.id):
                score_response: LLMScoreResponse = llm_service.generate_score(data_store.get_document(doc.id),
                                                                              query_rating_context.get_query_text(),
                                                                              config.relevance_scale,
                                                                              config.save_llm_explanation)
                data_store.add_rating_score(query_rating_context.get_query_id(),
                                            doc.id,
                                            score_response.get_score(),
                                            score_response.get_explanation())


if __name__ == "__main__":
    # configuration and logger definition
    args = parse_args()
    config: Config = Config.load(args.config_file)
    log: Logger = get_and_setup_logging(args.verbose)

    # setup
    data_store: DataStore = DataStore()
    search_engine: BaseSearchEngine = SearchEngineFactory.build(search_engine_type=config.search_engine_type,
                                                                endpoint=config.search_engine_collection_endpoint)
    llm: BaseChatModel = LLMServiceFactory.build(LLMConfig.load(config.llm_configuration_file))
    service: LLMService = LLMService(chat_model=llm)
    writer: AbstractWriter = WriterFactory.build(config.output_format, data_store)

    # pipeline starts
    add_user_queries(config, data_store)

    docs_to_generate_queries: List[Document] = search_engine.fetch_for_query_generation(
        documents_filter=config.documents_filter,
        doc_number=config.doc_number,
        doc_fields=config.doc_fields)
    log.debug(f"Number of documents retrieved for generation: {len(docs_to_generate_queries)}")

    generate_and_add_queries(config, data_store, service, docs_to_generate_queries)

    retrieve_and_add_documents(config, data_store, search_engine)

    add_cartesian_product_scores(config, data_store, service)

    writer.write(config.output_destination)

    log.info(f"Synthetic Dataset has been generated in: {config.output_destination}")

    if config.save_llm_explanation:
        data_store.export_all_records_with_explanation(config.llm_explanation_destination)
        log.info(f"Dataset with LLM explanation is saved into: {config.llm_explanation_destination}")
